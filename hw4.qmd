---
title: "Homework Assignment 4"
author: "Nicholas Pfeifer"
toc: true
number-sections: true
highlight-style: pygments
format: 
  html: 
    code-fold: true
    html-math-method: katex
    embed-resources: true
    self-contained-math: true
  pdf: 
    geometry: 
      - top=30mm
      - left=20mm
---

# Exercise 8

NYC Crash Data Cleaning The NYC motor vehicle collisions data with
documentation is available from NYC Open Data. The raw data needs some
cleaning.

## Part a.

Use the filter from the website to download the crash data of the
week of June 30, 2024 in CSV format; save it under a directory data with an
informative name (e.g., nyccrashes_2024w0630_by20240916.csv); read the data
into a Panda data frame with careful handling of the date time variables.

```{python}
import numpy as np
import pandas as pd

crash_df = pd.read_csv('data/nyccrashes_2024w0630_by20250212.csv',
                       dtype = {'ZIP CODE': str,
                                'LATITUDE': np.float32,
                                'LONGITUDE': np.float32})

crash_df
```

## Part b.

Clean up the variable names. Use lower cases and replace spaces with
underscores.

```{python}
crash_df.columns = crash_df.columns.str.lower().str.replace(' ', '_')

crash_df.head()
```

## Part c.

Check the crash date and time to see if they really match the
filter we intented. Remove the extra rows if needed.

## Part d.

Get the basic summaries of each variables: missing percentage;
descriptive statistics for continuous variables; frequency tables for
discrete variables.

**Missing Percentage**

```{python}
crash_df.isnull().mean()
```

**Descriptive Statistics for Continuous Variables**

```{python}
continuous_variables = ['latitude', 'longitude', 'number_of_persons_injured',
'number_of_persons_killed', 'number_of_pedestrians_injured',
'number_of_pedestrians_killed', 'number_of_cyclist_injured',
'number_of_cyclist_killed', 'number_of_motorist_injured',
'number_of_motorist_killed']

crash_df[continuous_variables].describe()
```

**Frequency Tables for Discrete Variables**

```{python}
discrete_variables = crash_df.drop(columns = continuous_variables).columns

for var in discrete_variables:
  var_freq = crash_df[var].value_counts(dropna=False)
  var_freq.columns = [var, 'count']
  print(var_freq)
```

## Part e.

Are their invalid longitude and latitude in the data? If so,
replace them with NA.

```{python}
crash_df[(crash_df['latitude'] == 0) | (crash_df['longitude'] == 0)]
```

There are 3 rows that have longitude and latitude values of 0.
Those coordinates not in New York City, so they are invalid.

```{python}
crash_df['latitude'] = crash_df['latitude'].replace(0, pd.NA)
crash_df['longitude'] = crash_df['longitude'].replace(0, pd.NA)
```

```{python}
crash_df.loc[[18, 378, 1560]]
```

## Part f.

Are there zip_code values that are not legit NYC zip codes? If so,
replace them with NA.

## Part g.

Are there missing in zip_code and borough? Do they always co-occur?

## Part h.

Are there cases where zip_code and borough are missing but the geo codes are
not missing? If so, fill in zip_code and borough using the geo codes.

## Part i.

Is it redundant to keep both location and the longitude/latitude at
the NYC Open Data server?

## Part j.

Check the frequency of crash_time by hour. Is there a matter of bad luck
at exactly midnight? How would you interpret this?

## Part k.

Are the number of persons killed/injured the summation of the numbers of
pedestrians, cyclist, and motorists killed/injured? If so, is it redundant
to keep these two columns at the NYC Open Data server?

## Part l.

Print the whole frequency table of contributing_factor_vehicle_1.
Convert lower cases to uppercases and check the frequencies again.

## Part m.

Provided an opportunity to meet the data provider, what suggestions
would you make based on your data exploration experience?